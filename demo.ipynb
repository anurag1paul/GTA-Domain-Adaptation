{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import itertools\n",
    "import pickle\n",
    "from enum import Enum\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import networks\n",
    "import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../Project/6_train/images/\"\n",
    "models = ['dual_gans_un', 'dual_gans_semi', 'cycle_gan_un', 'cycle_gan_semi', 'semantic']\n",
    "model_dict = defaultdict.fromkeys(models)\n",
    "model_dict_recon = defaultdict.fromkeys(models)\n",
    "image_size = 256\n",
    "batch_size = 2\n",
    "ngpu = torch.cuda.device_count()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    path = 'saved_models/test_' + models[i] + '_generator_b.pth'\n",
    "    model_dict[models[i]] = path\n",
    "    print(\"{} - {}\".format(models[i], path))\n",
    "    \n",
    "for i in range(len(models) - 1):\n",
    "    path = 'saved_models/test_' + models[i] + '_generator_a.pth'\n",
    "    model_dict_recon[models[i]] = path\n",
    "    print(\"{} - {}\".format(models[i], path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    return (image - torch.min(image))/(torch.max(image) - torch.min(image))\n",
    "\n",
    "def display_image(gta, cityscapes, gta_recon, semantic_sample):\n",
    "    for j in range(1):\n",
    "        image_output = torch.cat((gta[j,:,:,:].data, cityscapes[j,:,:,:].data, gta_recon[j,:,:,:].data, semantic_sample[j,:,:,:].data), -1).detach().cpu().numpy()\n",
    "        image = np.moveaxis(image_output, 0, -1)\n",
    "        plt.figure(figsize=(20,20))\n",
    "        plt.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_model():    \n",
    "    # Load the data\n",
    "    data = data_loader.DataLoader(data_root, image_size, batch_size)\n",
    "    \n",
    "    # Load the GTA to Cityscapes generator model for Dual Gans trained without any supervision \n",
    "    dual_gans_unsupervised = networks.DualGansGenerator().to(device)\n",
    "    dual_gans_unsupervised.load_state_dict(torch.load(model_dict[models[0]]))\n",
    "    # Load the Cityscapes to GTA generator model for Dual Gans trained without any supervision \n",
    "    dual_gans_unsupervised_recon = networks.DualGansGenerator().to(device)\n",
    "    dual_gans_unsupervised_recon.load_state_dict(torch.load(model_dict_recon[models[0]]))\n",
    "    \n",
    "    # Load the GTA to Cityscapes generator model for Dual Gans trained with 25% of labelled supervision \n",
    "    dual_gans_semisupervised = networks.DualGansGenerator().to(device)\n",
    "    dual_gans_semisupervised.load_state_dict(torch.load(model_dict[models[1]]))\n",
    "    # Load the Cityscapes to GTA generator model for Dual Gans trained with 25% of labelled supervision \n",
    "    dual_gans_semisupervised_recon = networks.DualGansGenerator().to(device)\n",
    "    dual_gans_semisupervised_recon.load_state_dict(torch.load(model_dict_recon[models[1]]))\n",
    "    \n",
    "    # Load the GTA to Cityscapes generator model for Cycle Gan trained without any supervision \n",
    "    cycle_gan_unsupervised = networks.CycleGanResnetGenerator().to(device)\n",
    "    cycle_gan_unsupervised.load_state_dict(torch.load(model_dict[models[2]]))\n",
    "    # Load the Cityscapes to GTA generator model for Cycle Gan trained without any supervision \n",
    "    cycle_gan_unsupervised_recon = networks.CycleGanResnetGenerator().to(device)\n",
    "    cycle_gan_unsupervised_recon.load_state_dict(torch.load(model_dict_recon[models[2]]))\n",
    "    \n",
    "    # Load the GTA to Cityscapes generator model for Cycle Gan trained with 25% of labelled supervision    \n",
    "    cycle_gan_semisupervised = networks.CycleGanResnetGenerator().to(device)\n",
    "    cycle_gan_semisupervised.load_state_dict(torch.load(model_dict[models[3]]))\n",
    "    # Load the Cityscapes to GTA generator model for Cycle Gan trained with 25% of labelled supervision\n",
    "    cycle_gan_semisupervised_recon = networks.CycleGanResnetGenerator().to(device)\n",
    "    cycle_gan_semisupervised_recon.load_state_dict(torch.load(model_dict_recon[models[3]]))\n",
    "   \n",
    "    # Load the Semantic Segmentation generator used for reporing F1 score results\n",
    "    semantic_model = networks.GeneratorUNet().to(device)\n",
    "    semantic_model.load_state_dict(torch.load(model_dict[models[-1]]))\n",
    "    \n",
    "    print('All Models loaded... \\n')\n",
    "    \n",
    "    x, y = next(data.data_generator(0, train = False))\n",
    "\n",
    "    gta_im = Variable(y, requires_grad = False).to(device)\n",
    "    gta_im = normalize(gta_im)\n",
    "    \n",
    "    print('Dual Gans Unsupervised - Original GTA image, Adapted Cityscapes image, Reconstructed GTA image, Segmented image')\n",
    "    cityscapes_dual_gans_un = dual_gans_unsupervised(gta_im)\n",
    "    cityscapes_dual_gans_un = normalize(cityscapes_dual_gans_un)\n",
    "    gta_dual_gans_un = dual_gans_unsupervised_recon(cityscapes_dual_gans_un)\n",
    "    gta_dual_gans_un = normalize(gta_dual_gans_un)\n",
    "    semantic_dual_gans_un = semantic_model(cityscapes_dual_gans_un)\n",
    "    semantic_dual_gans_un = normalize(semantic_dual_gans_un)\n",
    "    display_image(gta_im, cityscapes_dual_gans_un, gta_dual_gans_un, semantic_dual_gans_un)\n",
    "\n",
    "    print('Dual Gans Semisuervised - Original GTA image, Adapted Cityscapes image, Reconstructed GTA image, Segmented image')\n",
    "    cityscapes_dual_gans_semi = dual_gans_semisupervised(gta_im)\n",
    "    cityscapes_dual_gans_semi = normalize(cityscapes_dual_gans_semi)\n",
    "    gta_dual_gans_semi = dual_gans_semisupervised_recon(cityscapes_dual_gans_semi)\n",
    "    gta_dual_gans_semi = normalize(gta_dual_gans_semi)\n",
    "    semantic_dual_gans_semi = semantic_model(cityscapes_dual_gans_semi)\n",
    "    semantic_dual_gans_semi = normalize(semantic_dual_gans_semi)\n",
    "    display_image(gta_im, cityscapes_dual_gans_semi, gta_dual_gans_semi, semantic_dual_gans_semi)\n",
    "    \n",
    "    print('Cycle Gan Unsupervised - Original GTA image, Adapted Cityscapes image, Reconstructed GTA image, Segmented image')\n",
    "    cityscapes_cycle_gan_un = cycle_gan_unsupervised(gta_im)\n",
    "    cityscapes_cycle_gan_un = normalize(cityscapes_cycle_gan_un)\n",
    "    gta_cycle_gan_un = cycle_gan_unsupervised_recon(cityscapes_cycle_gan_un)\n",
    "    gta_cycle_gan_un = normalize(gta_cycle_gan_un)\n",
    "    semantic_cycle_gan_un = semantic_model(cityscapes_cycle_gan_un)\n",
    "    semantic_cycle_gan_un = normalize(semantic_cycle_gan_un)\n",
    "    display_image(gta_im, cityscapes_cycle_gan_un, gta_cycle_gan_un, semantic_cycle_gan_un)\n",
    "    \n",
    "    print('Cycle Gan Semisuervised - Original GTA image, Adapted Cityscapes image, Reconstructed GTA image, Segmented image')\n",
    "    cityscapes_cycle_gan_semi = cycle_gan_semisupervised(gta_im)\n",
    "    cityscapes_cycle_gan_semi = normalize(cityscapes_cycle_gan_semi)\n",
    "    gta_cycle_gan_semi = cycle_gan_semisupervised_recon(cityscapes_cycle_gan_semi)\n",
    "    gta_cycle_gan_semi = normalize(gta_cycle_gan_semi)\n",
    "    semantic_cycle_gan_semi = semantic_model(cityscapes_cycle_gan_semi)\n",
    "    semantic_cycle_gan_semi = normalize(semantic_cycle_gan_semi)\n",
    "    display_image(gta_im, cityscapes_cycle_gan_semi, gta_cycle_gan_semi, semantic_cycle_gan_semi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
