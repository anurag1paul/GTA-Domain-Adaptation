{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from data_loader import DataLoader\n",
    "from networks import GeneratorUNet, GeneratorResNet, Discriminator, ResNetBlock\n",
    "from utils import ensure_dir, get_opts, weights_init_normal, sample_images\n",
    "from logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "data = DataLoader(data_root='../gta/', image_size=(512, 512), batch_size=16)\n",
    "opt = get_opts()\n",
    "\n",
    "ensure_dir('saved_images/%s' % 'GTA')\n",
    "ensure_dir('saved_models/%s' % 'GTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss().to(device)\n",
    "criterion_pixelwise = torch.nn.L1Loss().to(device)\n",
    "\n",
    "lambda_pixel = 10\n",
    "\n",
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "generator = torch.nn.DataParallel(generator, list(range(torch.cuda.device_count())))\n",
    "discriminator = torch.nn.DataParallel(discriminator, list(range(torch.cuda.device_count())))\n",
    "\n",
    "if opt['load_model']:\n",
    "    if os.path.isfile(\"saved_models/generator.pth\"):\n",
    "        generator.load_state_dict(torch.load(\"saved_models/generator.pth\"))\n",
    "    if os.path.isfile(\"saved_models/discriminator.pth\"):\n",
    "        discriminator.load_state_dict(torch.load(\"saved_models/discriminator.pth\"))\n",
    "else:\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt[\"lr\"], betas=(opt[\"b1\"], opt[\"b2\"]))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt[\"lr\"], betas=(opt[\"b1\"], opt[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 0/390] [Discriminator loss: 0.251297682524] [Generator loss: 5.08419752121, pixel-wise loss: 0.489195734262, adversarial loss: 0.192240446806]\n",
      "[Epoch 0/100] [Batch 1/390] [Discriminator loss: 0.153247758746] [Generator loss: 5.10683488846, pixel-wise loss: 0.452323555946, adversarial loss: 0.583599507809]\n",
      "[Epoch 0/100] [Batch 2/390] [Discriminator loss: 0.115049213171] [Generator loss: 4.78188800812, pixel-wise loss: 0.438061743975, adversarial loss: 0.401270568371]\n",
      "[Epoch 0/100] [Batch 3/390] [Discriminator loss: 0.0980287864804] [Generator loss: 5.01095676422, pixel-wise loss: 0.433087855577, adversarial loss: 0.680078208447]\n",
      "[Epoch 0/100] [Batch 4/390] [Discriminator loss: 0.0745335966349] [Generator loss: 4.76935863495, pixel-wise loss: 0.423321455717, adversarial loss: 0.536144018173]\n",
      "[Epoch 0/100] [Batch 5/390] [Discriminator loss: 0.0308257751167] [Generator loss: 5.24075078964, pixel-wise loss: 0.442306756973, adversarial loss: 0.81768321991]\n",
      "[Epoch 0/100] [Batch 6/390] [Discriminator loss: 0.0206155125052] [Generator loss: 5.04116868973, pixel-wise loss: 0.425496816635, adversarial loss: 0.786200404167]\n",
      "[Epoch 0/100] [Batch 7/390] [Discriminator loss: 0.0173787530512] [Generator loss: 4.78005552292, pixel-wise loss: 0.40368938446, adversarial loss: 0.743161797523]\n",
      "[Epoch 0/100] [Batch 8/390] [Discriminator loss: 0.0173568204045] [Generator loss: 4.89218473434, pixel-wise loss: 0.402913719416, adversarial loss: 0.863047480583]\n",
      "[Epoch 0/100] [Batch 9/390] [Discriminator loss: 0.0208018794656] [Generator loss: 4.63063955307, pixel-wise loss: 0.39003765583, adversarial loss: 0.73026317358]\n",
      "[Epoch 0/100] [Batch 10/390] [Discriminator loss: 0.103730387986] [Generator loss: 4.504529953, pixel-wise loss: 0.35534080863, adversarial loss: 0.95112156868]\n",
      "[Epoch 0/100] [Batch 11/390] [Discriminator loss: 0.44685035944] [Generator loss: 3.40686202049, pixel-wise loss: 0.339971154928, adversarial loss: 0.00715031195432]\n",
      "[Epoch 0/100] [Batch 12/390] [Discriminator loss: 0.256181001663] [Generator loss: 3.62579035759, pixel-wise loss: 0.346262216568, adversarial loss: 0.163168221712]\n",
      "[Epoch 0/100] [Batch 13/390] [Discriminator loss: 0.236145794392] [Generator loss: 4.45055818558, pixel-wise loss: 0.350011616945, adversarial loss: 0.950442194939]\n",
      "[Epoch 0/100] [Batch 14/390] [Discriminator loss: 0.173258557916] [Generator loss: 4.06437921524, pixel-wise loss: 0.319547623396, adversarial loss: 0.868902921677]\n",
      "[Epoch 0/100] [Batch 15/390] [Discriminator loss: 0.123463459313] [Generator loss: 3.46630835533, pixel-wise loss: 0.304048866034, adversarial loss: 0.425819694996]\n",
      "[Epoch 0/100] [Batch 16/390] [Discriminator loss: 0.0697104409337] [Generator loss: 3.56305837631, pixel-wise loss: 0.296214908361, adversarial loss: 0.600909113884]\n",
      "[Epoch 0/100] [Batch 17/390] [Discriminator loss: 0.109893195331] [Generator loss: 3.65687799454, pixel-wise loss: 0.278778880835, adversarial loss: 0.869089007378]\n",
      "[Epoch 0/100] [Batch 18/390] [Discriminator loss: 0.175190016627] [Generator loss: 2.99857640266, pixel-wise loss: 0.273519784212, adversarial loss: 0.263378709555]\n",
      "[Epoch 0/100] [Batch 19/390] [Discriminator loss: 0.148271366954] [Generator loss: 3.55950093269, pixel-wise loss: 0.262809067965, adversarial loss: 0.931410253048]\n",
      "[Epoch 0/100] [Batch 20/390] [Discriminator loss: 0.0802716687322] [Generator loss: 3.03523111343, pixel-wise loss: 0.257428854704, adversarial loss: 0.460942536592]\n",
      "[Epoch 0/100] [Batch 21/390] [Discriminator loss: 0.0737158358097] [Generator loss: 3.05398440361, pixel-wise loss: 0.244157031178, adversarial loss: 0.612414062023]\n",
      "[Epoch 0/100] [Batch 22/390] [Discriminator loss: 0.111511975527] [Generator loss: 3.06917333603, pixel-wise loss: 0.236579760909, adversarial loss: 0.703375697136]\n",
      "[Epoch 0/100] [Batch 23/390] [Discriminator loss: 0.218736633658] [Generator loss: 2.5020711422, pixel-wise loss: 0.228588148952, adversarial loss: 0.216189533472]\n",
      "[Epoch 0/100] [Batch 24/390] [Discriminator loss: 0.462906390429] [Generator loss: 3.2276597023, pixel-wise loss: 0.223302617669, adversarial loss: 0.994633555412]\n",
      "[Epoch 0/100] [Batch 25/390] [Discriminator loss: 0.471406638622] [Generator loss: 3.03940606117, pixel-wise loss: 0.204204022884, adversarial loss: 0.997365653515]\n",
      "[Epoch 0/100] [Batch 26/390] [Discriminator loss: 0.369359463453] [Generator loss: 3.04255437851, pixel-wise loss: 0.205370619893, adversarial loss: 0.988848090172]\n",
      "[Epoch 0/100] [Batch 27/390] [Discriminator loss: 0.151357978582] [Generator loss: 2.36880612373, pixel-wise loss: 0.183817967772, adversarial loss: 0.530626356602]\n",
      "[Epoch 0/100] [Batch 28/390] [Discriminator loss: 0.284704208374] [Generator loss: 1.8587526083, pixel-wise loss: 0.173913180828, adversarial loss: 0.119620755315]\n",
      "[Epoch 0/100] [Batch 29/390] [Discriminator loss: 0.153423458338] [Generator loss: 1.96396946907, pixel-wise loss: 0.150465875864, adversarial loss: 0.459310799837]\n",
      "[Epoch 0/100] [Batch 30/390] [Discriminator loss: 0.166476219893] [Generator loss: 2.17965507507, pixel-wise loss: 0.150948867202, adversarial loss: 0.670166373253]\n",
      "[Epoch 0/100] [Batch 31/390] [Discriminator loss: 0.220881447196] [Generator loss: 1.78331804276, pixel-wise loss: 0.162870913744, adversarial loss: 0.154608935118]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-567d3fa92706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25000\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mreal_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/6_train/GTA-Domain-Adaptation/data_loader.pyc\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/6_train/GTA-Domain-Adaptation/data_loader.pyc\u001b[0m in \u001b[0;36mimage_loader\u001b[0;34m(self, image_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;34m\"\"\"load image, returns cuda tensor\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#this is for VGG, may not be needed for ResNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/.local/lib/python2.7/site-packages/torchvision/transforms/transforms.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/.local/lib/python2.7/site-packages/torchvision/transforms/transforms.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/.local/lib/python2.7/site-packages/torchvision/transforms/functional.pyc\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/.local/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBa'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGBA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/21/321/mbilkhu/.local/lib/python2.7/site-packages/PIL/ImageFile.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(opt['n_epochs']):\n",
    "    for i in range(25000 // opt['batch_size']):\n",
    "\n",
    "        y, x = next(data.data_generator())\n",
    "\n",
    "        real_A = Variable(x.type(Tensor))\n",
    "        real_B = Variable(y.type(Tensor))\n",
    "\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), 1))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), 1))), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        fake_B = generator(real_A)\n",
    "        pred_fake = discriminator(fake_B)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "\n",
    "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(real_B)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        pred_fake = discriminator(fake_B.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        message = (\"\\r[Epoch {}/{}] [Batch {}/{}] [Discriminator loss: {}] [Generator loss: {}, pixel-wise loss: {}, adversarial loss: {}]\"\n",
    "                .format(epoch, opt[\"n_epochs\"], i, 25000//opt[\"batch_size\"],\n",
    "                        loss_D.item(), loss_G.item(), loss_pixel.item(), loss_GAN.item()))\n",
    "        print(message)\n",
    "        logger.info(message)\n",
    "\n",
    "        if i % opt[\"sample_interval\"] == 0:\n",
    "            sample_images(data, i, generator, \"{}-{}\".format(epoch,i))\n",
    "\n",
    "    if opt['checkpoint_interval'] != -1 and epoch % opt['checkpoint_interval'] == 0:\n",
    "        torch.save(generator.state_dict(), 'saved_models/generator.pth')\n",
    "        torch.save(discriminator.state_dict(), 'saved_models/discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
