{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Domain Adaptation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from data_loader import DataLoader\n",
    "from networks import GeneratorUNet, GeneratorResNet, Discriminator, ResNetBlock\n",
    "from utils import ensure_dir, get_opts, weights_init_normal, sample_images\n",
    "from logger import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup few parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataloader and load hyperparameters\n",
    "\n",
    "The path to the dataset containing training images and labels needs to be provided here. <br>\n",
    "Parameters used in training are defined in *params.yaml*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(data_root='../gta/', image_size=(512, 512), batch_size=16)\n",
    "opt = get_opts()\n",
    "\n",
    "ensure_dir('saved_images/%s' % 'GTA')\n",
    "ensure_dir('saved_models/%s' % 'GTA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = torch.nn.MSELoss().to(device)\n",
    "criterion_pixelwise = torch.nn.L1Loss().to(device)\n",
    "\n",
    "lambda_pixel = 10\n",
    "\n",
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "generator = torch.nn.DataParallel(generator, list(range(torch.cuda.device_count())))\n",
    "discriminator = torch.nn.DataParallel(discriminator, list(range(torch.cuda.device_count())))\n",
    "\n",
    "if opt['load_model']:\n",
    "    if os.path.isfile(\"saved_models/generator.pth\"):\n",
    "        generator.load_state_dict(torch.load(\"saved_models/generator.pth\"))\n",
    "    if os.path.isfile(\"saved_models/discriminator.pth\"):\n",
    "        discriminator.load_state_dict(torch.load(\"saved_models/discriminator.pth\"))\n",
    "else:\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define optimizer for generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt[\"lr\"], betas=(opt[\"b1\"], opt[\"b2\"]))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt[\"lr\"], betas=(opt[\"b1\"], opt[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(opt['n_epochs']):\n",
    "    for i in range(25000 // opt['batch_size']):\n",
    "\n",
    "        y, x = next(data.data_generator())\n",
    "\n",
    "        real_A = Variable(x.type(Tensor))\n",
    "        real_B = Variable(y.type(Tensor))\n",
    "\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), 1))), requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), 1))), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        fake_B = generator(real_A)\n",
    "        pred_fake = discriminator(fake_B)\n",
    "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "        loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "\n",
    "        loss_G = loss_GAN + lambda_pixel * loss_pixel\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(real_B)\n",
    "        loss_real = criterion_GAN(pred_real, valid)\n",
    "        pred_fake = discriminator(fake_B.detach())\n",
    "        loss_fake = criterion_GAN(pred_fake, fake)\n",
    "\n",
    "        loss_D = 0.5 * (loss_real + loss_fake)\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        message = (\"\\r[Epoch {}/{}] [Batch {}/{}] [Discriminator loss: {}] [Generator loss: {}, pixel-wise loss: {}, adversarial loss: {}]\"\n",
    "                .format(epoch, opt[\"n_epochs\"], i, 25000//opt[\"batch_size\"],\n",
    "                        loss_D.item(), loss_G.item(), loss_pixel.item(), loss_GAN.item()))\n",
    "        print(message)\n",
    "        logger.info(message)\n",
    "\n",
    "        if i % opt[\"sample_interval\"] == 0:\n",
    "            sample_images(data, i, generator, \"{}-{}\".format(epoch,i))\n",
    "\n",
    "    if opt['checkpoint_interval'] != -1 and epoch % opt['checkpoint_interval'] == 0:\n",
    "        torch.save(generator.state_dict(), 'saved_models/generator.pth')\n",
    "        torch.save(discriminator.state_dict(), 'saved_models/discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
